{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting several classifiers for spam detection\n",
    "\n",
    "This notebook provides several examples of classification using algorithms alone or combined in an ensemble. No emphasis is  on tuning or parameter optimization just yet. Therefore, most of the model classes are instantiated with default parameters. Naive bayes is set as the base benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 04C4-F2DC\n",
      "\n",
      " Directory of C:\\Users\\Guillermo\\Desktop\\Udacity_DSN\\py_exercises\\spam_clasifier\n",
      "\n",
      "12/28/2018  02:42 PM    <DIR>          .\n",
      "12/28/2018  02:42 PM    <DIR>          ..\n",
      "12/28/2018  02:42 PM    <DIR>          .ipynb_checkpoints\n",
      "12/28/2018  01:14 PM             5,868 readme\n",
      "12/28/2018  01:14 PM           477,907 SMSSpamCollection\n",
      "12/28/2018  02:42 PM           530,182 Spam Classification.ipynb\n",
      "               3 File(s)      1,013,957 bytes\n",
      "               3 Dir(s)  332,797,198,336 bytes free\n",
      "['ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\n', 'ham\\tOk lar... Joking wif u oni...\\n', \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# A first look at the data:\n",
    "#import os\n",
    "#print(os.getcwd()+\"\\\\SMSSpamCollection\")\n",
    "\n",
    "%ls\n",
    "with open(\"SMSSpamCollection\",\"r\") as data:\n",
    "    print(data.readlines()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data pre-processing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Read data in:\n",
    "df= pd.read_table(\"SMSSpamCollection\", header=None, sep='\\t', names=['label','sms_message'])\n",
    "\n",
    "# Make response numerical:\n",
    "df['label']= df.label.map({'ham':0, 'spam':1})\n",
    "\n",
    "# Split dataset in training and testing:\n",
    "X_train, X_test, y_train, y_test= train_test_split(df['sms_message'],\n",
    "                                                   df['label'],\n",
    "                                                   random_state=1)\n",
    "# Convert text into a bag of words in matrix form:\n",
    "count_vector= CountVectorizer()\n",
    "training_data= count_vector.fit_transform(X_train)\n",
    "testing_data= count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes performance metrics\n",
      "\n",
      "Accuracy score:  0.9885139985642498\n",
      "Precision score:  0.9720670391061452\n",
      "Recall score:  0.9405405405405406\n",
      "F1 score:  0.9560439560439562\n"
     ]
    }
   ],
   "source": [
    "######### NAIVE BAYES CLASSIFIER ###########################################################\n",
    "## Insert a cell above explaining the nuts and bolts of the Naive Bayes algorithm.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes= MultinomialNB()\n",
    "\n",
    "# Naive Bayes fitting:\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "# Naive Bayes testing:\n",
    "predictions= naive_bayes.predict(testing_data)\n",
    "\n",
    "# Evaluate performance:\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Naive Bayes performance metrics\\n')\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.2, n_estimators=300, random_state=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Ensemble methods ###############\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instatitate each with default hyper-parameters (only n_estimators or weak_learners for now (n=200))\n",
    "bag_class= BaggingClassifier(n_estimators=200)\n",
    "rf_class= RandomForestClassifier(n_estimators=200)\n",
    "ada_class= AdaBoostClassifier(n_estimators=300, learning_rate=0.2)\n",
    "\n",
    "# Fitting each instance of a classification ensemble:\n",
    "#X_train, X_test, y_train, y_test\n",
    "bag_class.fit(X= training_data, y=y_train)\n",
    "rf_class.fit(X= training_data, y= y_train)\n",
    "ada_class.fit(X= training_data, y= y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model testing:\n",
    "bag_preds= bag_class.predict(X=testing_data)\n",
    "rf_preds= rf_class.predict(X=testing_data)\n",
    "ada_preds= ada_class.predict(X=testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble classifiers --- Model Evaluation:\n",
    "def print_metrics(y_true, preds, model_name=None):\n",
    "    '''\n",
    "    A function to report model agreement\n",
    "    Inputs: y_true= actual values (np array or pd Series)\n",
    "            preds= predictions from a model (np array or pd Series)\n",
    "    Output: Accuracy, precision, recall, F1\n",
    "    '''\n",
    "    if model_name == None:\n",
    "        print('Accuracy : ', format(accuracy_score(y_true, preds)))\n",
    "        print('Precision : ', format(precision_score(y_true, preds)))\n",
    "        print('Recall : ', format(recall_score(y_true, preds)))\n",
    "        print('F1 : ', format(f1_score(y_true, preds)))\n",
    "    else:\n",
    "        print('Model performace for ' + model_name)\n",
    "        print('Accuracy : ', format(accuracy_score(y_true, preds)))\n",
    "        print('Precision : ', format(precision_score(y_true, preds)))\n",
    "        print('Recall : ', format(recall_score(y_true, preds)))\n",
    "        print('F1 : ', format(f1_score(y_true, preds)))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performace for Naive Bayes\n",
      "Accuracy :  0.9885139985642498\n",
      "Precision :  0.9720670391061452\n",
      "Recall :  0.9405405405405406\n",
      "F1 :  0.9560439560439562\n",
      "\n",
      "\n",
      "Model performace for Bagging, n=200\n",
      "Accuracy :  0.9763101220387652\n",
      "Precision :  0.9222222222222223\n",
      "Recall :  0.8972972972972973\n",
      "F1 :  0.9095890410958904\n",
      "\n",
      "\n",
      "Model performace for Random Forest, n=200\n",
      "Accuracy :  0.9820531227566404\n",
      "Precision :  1.0\n",
      "Recall :  0.8648648648648649\n",
      "F1 :  0.927536231884058\n",
      "\n",
      "\n",
      "Model performace for AdaBoost, n=300\n",
      "Accuracy :  0.9770279971284996\n",
      "Precision :  0.9693251533742331\n",
      "Recall :  0.8540540540540541\n",
      "F1 :  0.9080459770114943\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test above:\n",
    "print_metrics(y_test, predictions, model_name='Naive Bayes')\n",
    "print_metrics(y_test, bag_preds, model_name='Bagging, n=200')\n",
    "print_metrics(y_test, rf_preds, model_name='Random Forest, n=200')\n",
    "print_metrics(y_test, ada_preds, model_name='AdaBoost, n=300')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
